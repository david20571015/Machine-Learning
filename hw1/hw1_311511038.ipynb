{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_x_df = pd.read_csv('X.csv')\n",
    "data_t_df = pd.read_csv('T.csv')\n",
    "data_df = pd.concat([data_x_df, data_t_df], axis=1)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(data_df)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "train_ratio = 0.9\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "\n",
    "train_feature = dataset[:train_size, :-1]\n",
    "test_feature = dataset[train_size:, :-1]\n",
    "train_target = dataset[:train_size, -1]\n",
    "test_target = dataset[train_size:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_weight(phi, target):\n",
    "    return np.linalg.pinv(phi) @ target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M = 1\n",
    "\n",
    "$$ y(\\textbf{x}, \\textbf{w}) = \\textit{w}_{0} + \\sum_{\\textit{i} = 1}^{D} \\textit{w}_{i}\\textit{x}_{i}  = \\textbf{w}^{T} \\phi(x) $$\n",
    "where\n",
    "$$ \\textbf{w} = \\begin{pmatrix} \\textit{w}_{0} & \\textit{w}_{1} & ... & \\textit{w}_{D} \\end{pmatrix}^{T} $$\n",
    "$$ \\phi(x) = \\begin{pmatrix} 1 & \\textit{x}_{1} & ... & \\textit{x}_{D}  \\end{pmatrix}^{T} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_m1(features):\n",
    "    \"\"\"Computes phi matrix with m = 1.\n",
    "    \n",
    "    Args:\n",
    "        features: np.ndarray with shape (n_samples, n_features)\n",
    "        \n",
    "    Returns:\n",
    "        phi: np.ndarray with shape (n_samples, 1 + n_features)\n",
    "    \"\"\"\n",
    "    m_0 = np.ones((features.shape[0], 1))  # 1\n",
    "    m_1 = features  # x_1, x_2, ..., x_D\n",
    "    return np.concatenate((m_0, m_1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phi_m1 = phi_m1(train_feature)\n",
    "test_phi_m1 = phi_m1(test_feature)\n",
    "\n",
    "w_m1 = optimal_weight(train_phi_m1, train_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M = 2\n",
    "\n",
    "$$ y(\\textbf{x}, \\textbf{w}) = \\textit{w}_{0} + \\sum_{\\textit{i} = 1}^{D} \\textit{w}_{i}\\textit{x}_{i} + \\sum_{\\textit{i} = 1}^{D} \\sum_{\\textit{j} = 1}^{D} \\textit{w}_{ij}\\textit{x}_{i}\\textit{x}_{j} = \\textbf{w}^{T} \\phi(x) $$\n",
    "where\n",
    "$$ \\textbf{w} = \\begin{pmatrix} \\textit{w}_{0} & \\textit{w}_{1} & ... & \\textit{w}_{D} & \\textit{w}_{11} & \\textit{w}_{12} & ... & \\textit{w}_{DD} \\end{pmatrix}^{T} $$\n",
    "$$ \\phi(x) = \\begin{pmatrix} 1 & \\textit{x}_{1} & ... & \\textit{x}_{D} & \\textit{x}_{1}\\textit{x}_{1} & \\textit{x}_{1}\\textit{x}_{2} & ... & \\textit{x}_{D}\\textit{x}_{D} \\end{pmatrix}^{T} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_m2(features):\n",
    "    \"\"\"Computes phi matrix with m = 2.\n",
    "    \n",
    "    Args:\n",
    "        features: np.ndarray with shape (n_samples, n_features)\n",
    "        \n",
    "    Returns:\n",
    "        phi: np.ndarray with shape (n_samples, 1 + n_features + n_features ** 2)\n",
    "    \"\"\"\n",
    "    m_0 = np.ones((features.shape[0], 1))  # 1\n",
    "    m_1 = features  # x_1, x_2, ..., x_D\n",
    "\n",
    "    # x_1^2, x_1x_2, ..., x_1x_D, x_2^2, x_2x_3, ..., x_2x_D, ..., x_D^2\n",
    "    m_2 = np.expand_dims(features, axis=-1) @ np.expand_dims(features, axis=-2)\n",
    "    m_2 = m_2.reshape(m_2.shape[0], -1)\n",
    "    return np.concatenate((m_0, m_1, m_2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phi_m2 = phi_m2(train_feature)\n",
    "test_phi_m2 = phi_m2(test_feature)\n",
    "\n",
    "w_m2 = optimal_weight(train_phi_m2, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_square_error(y, t):\n",
    "    return np.sqrt(np.mean((y - t)**2))\n",
    "\n",
    "\n",
    "train_rms_m1 = root_mean_square_error(train_phi_m1 @ w_m1, train_target)\n",
    "test_rms_m1 = root_mean_square_error(test_phi_m1 @ w_m1, test_target)\n",
    "\n",
    "train_rms_m2 = root_mean_square_error(train_phi_m2 @ w_m2, train_target)\n",
    "test_rms_m2 = root_mean_square_error(test_phi_m2 @ w_m2, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train rms m1: {train_rms_m1}')\n",
    "print(f'test rms m1: {test_rms_m1}')\n",
    "print(f'train rms m2: {train_rms_m2}')\n",
    "print(f'test rms m2: {test_rms_m2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Analysis of M = 1\n",
    "\n",
    "I used the weight of the model to analyze the importance of each feature. The weight of the model is the coefficient of each feature. The larger the weight is, the more important the feature is.\n",
    "\n",
    "> The weight with index 0 is not considered as a feature because it is the bias of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'w_m1: {w_m1}')\n",
    "abs_importance = np.abs(w_m1[1:])\n",
    "importance_rank = np.argsort(abs_importance)[::-1]\n",
    "print(f'Rank of features\\' contribution: {importance_rank}')\n",
    "print(f'The most important feature: {data_df.columns[importance_rank[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Maximum Likelihood Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(features):\n",
    "    \"\"\"Computes the mean and standard deviation of each feature.\n",
    "    \n",
    "    Args:\n",
    "        features: np.ndarray with shape (n_samples, n_features)\n",
    "        \n",
    "    Returns:\n",
    "        mean: np.ndarray with shape (1, n_features)\n",
    "        std: np.ndarray with shape (1, n_features)\n",
    "    \"\"\"\n",
    "    mean = np.mean(features, axis=0, keepdims=True)\n",
    "    std = np.std(features, axis=0, keepdims=True)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def phi_gaussian(features, mean, std):\n",
    "    \"\"\"Computes the Gaussian phi.\n",
    "    \n",
    "    Args:\n",
    "        features: np.ndarray with shape (n_samples, n_features)\n",
    "        mean: np.ndarray with shape (1, n_features)\n",
    "        std: np.ndarray with shape (1, n_features)\n",
    "        \n",
    "    Returns:\n",
    "        phi: np.ndarray with shape (n_samples, 1 + n_features)\n",
    "    \"\"\"\n",
    "    gaussians = np.exp(-((features - mean) / std)**2 / 2)\n",
    "    return np.concatenate((np.ones((features.shape[0], 1)), gaussians), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = get_mean_and_std(train_feature)\n",
    "train_phi_gaussian = phi_gaussian(train_feature, train_mean, train_std)\n",
    "test_phi_gaussian = phi_gaussian(test_feature, train_mean, train_std)\n",
    "\n",
    "w_gaussian = optimal_weight(train_phi_gaussian, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rms_gaussian = root_mean_square_error(train_phi_gaussian @ w_gaussian, train_target)\n",
    "test_rms_gaussian = root_mean_square_error(test_phi_gaussian @ w_gaussian, test_target)\n",
    "\n",
    "print(f'train rms gaussian: {train_rms_gaussian}')\n",
    "print(f'test rms gaussian: {test_rms_gaussian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Maximum A Posteriori Approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('hw1-nKNpIY9G-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9347332e7fffacb469f6b61eb89afbd5d1cb4d5d929849d41d99be57377ebf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
