{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML HW3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import svm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./x_train.csv', header=None) / 255.0\n",
    "data = np.array(data)\n",
    "data = data - np.mean(data, axis=0)\n",
    "\n",
    "label = pd.read_csv('./t_train.csv', header=None)\n",
    "label = np.array(label)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    eigenvalues: np.ndarray\n",
    "    eigenvectors: np.ndarray\n",
    "\n",
    "    def __init__(self, n_components) -> None:\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (n_samples, n_features)\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        u, s, vh = np.linalg.svd(x, full_matrices=False)\n",
    "        self.eigenvalues = np.square(s) / (x.shape[0] - 1)\n",
    "        self.eigenvectors = vh.T[:, :self.n_components]\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (n_samples, n_features)\n",
    "        Returns:\n",
    "            (n_samples, n_components)\n",
    "        \"\"\"\n",
    "        return x @ self.eigenvectors\n",
    "\n",
    "    def fit_transform(self, x):\n",
    "        return self.fit(x).transform(x)\n",
    "\n",
    "    def components(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            (n_components, n_features)\n",
    "        \"\"\"\n",
    "        return self.eigenvectors.T\n",
    "\n",
    "    def explained_variance(self):\n",
    "        return self.eigenvalues[:self.n_components]\n",
    "\n",
    "    def explained_variance_ratio(self):\n",
    "        return self.eigenvalues[:self.n_components] / np.sum(self.eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(data)\n",
    "print(pca_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Approaches\n",
    "\n",
    "1. one-vs-one\n",
    "\n",
    "   Choose two classes each time, and train a binary classifier for each pair of classes. Then, for a new sample, we can use the binary classifiers to predict the class of the sample. Finally, we can choose the class that has the most votes.\n",
    "\n",
    "2. one-vs-rest\n",
    "\n",
    "   Choose one class as the positive class, and the rest as the negative class. Then, we can train a binary classifier for each class. Finally, we can choose the class that has the most votes.\n",
    "\n",
    "In this case, both approaches will train three binary classifiers. Here. I will use **one-vs-one** approach because it use only two classes of data each time, and it is more efficient than one-vs-rest approach.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "class Kernel:\n",
    "\n",
    "    def __init__(self, mode: Literal['Linear', 'Polynomial']) -> None:\n",
    "        if mode not in ['Linear', 'Polynomial']:\n",
    "            raise ValueError(f'Unknown mode: {mode}, should be `Linear` or `Polynomial`')\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "    def phi(self, x: np.ndarray):\n",
    "        if self.mode == 'Linear':\n",
    "            return x\n",
    "        else:  # self.mode == 'Polynomial':\n",
    "            return np.array([\n",
    "                np.square(x[..., 0]),\n",
    "                np.sqrt(2) * x[..., 0] * x[..., 1],\n",
    "                np.square(x[..., 1]),\n",
    "            ]).T\n",
    "\n",
    "    def compute_kernel(self, x1, x2):\n",
    "        return self.phi(x1) @ self.phi(x2).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    coef: np.ndarray\n",
    "    sv_idx: np.ndarray\n",
    "    weight: np.ndarray\n",
    "    bias: np.floating\n",
    "\n",
    "    def __init__(self, pos_cls, neg_cls, kernel: Kernel, C=1.0) -> None:\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.pos_cls = pos_cls\n",
    "        self.neg_cls = neg_cls\n",
    "\n",
    "    def compute_weight_and_bias(self, alpha, x, y):\n",
    "        weight = (alpha * y).T @ self.kernel.phi(x)\n",
    "\n",
    "        m_idx = np.bitwise_and(self.C > alpha, alpha > 0).reshape(-1)\n",
    "        s_idx = (alpha != 0).reshape(-1)\n",
    "        kernels = self.kernel.compute_kernel(x[m_idx], x[s_idx])\n",
    "        bias = np.mean(y[m_idx] - kernels @ (alpha * y)[s_idx]) if len(m_idx) > 0 else 0.0\n",
    "\n",
    "        return weight, bias\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        y = np.where(y == self.pos_cls, 1, -1)\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "        if self.kernel.mode == 'Linear':\n",
    "            clf = SVC(kernel='linear', C=self.C, decision_function_shape='ovo')\n",
    "        else:  # self.kernel.mode == 'Linear'\n",
    "            clf = SVC(kernel='poly', C=self.C, degree=2, decision_function_shape='ovo')\n",
    "        clf.fit(x, y)\n",
    "\n",
    "        self.coef = np.abs(clf.dual_coef_.T)\n",
    "        self.sv_idx = clf.support_\n",
    "        alpha = np.zeros_like(y)\n",
    "        alpha[self.sv_idx] = self.coef\n",
    "        self.weight, self.bias = self.compute_weight_and_bias(alpha, x, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = np.sign(self.kernel.phi(x) @ self.weight.T + self.bias)\n",
    "        return np.where(pred == 1, self.pos_cls, self.neg_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(y):\n",
    "    classes = np.arange(3)\n",
    "    counts = np.empty((y.shape[0], 3))\n",
    "    for cls in classes:\n",
    "        counts[:, cls] = np.sum(y == cls, axis=-1)\n",
    "\n",
    "    return np.argmax(counts, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_kernel = Kernel(mode='Linear')\n",
    "C = 1.0\n",
    "linear_svm = []\n",
    "\n",
    "for c1, c2 in [[0, 1], [0, 2], [1, 2]]:\n",
    "    idx = np.logical_or(label == c1, label == c2).reshape(-1)\n",
    "    x = pca_data[idx]\n",
    "    y = label[idx]\n",
    "    linear_svm.append(SVM(c1, c2, linear_kernel, C=C).fit(x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot(x, y, y_pred, sv_idx, xx, yy, title):\n",
    "    c1_idx = np.where(y == 0)\n",
    "    c2_idx = np.where(y == 1)\n",
    "    c3_idx = np.where(y == 2)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(title)\n",
    "    plt.scatter(x[sv_idx, 0],\n",
    "                x[sv_idx, 1],\n",
    "                facecolors='none',\n",
    "                edgecolors='k',\n",
    "                linewidths=1.25,\n",
    "                label='Support Vector')\n",
    "    plt.scatter(x[c1_idx, 0], x[c1_idx, 1], c='r', marker='x', label='T-shirt/top')\n",
    "    plt.scatter(x[c2_idx, 0], x[c2_idx, 1], c='b', marker='x', label='Trouser')\n",
    "    plt.scatter(x[c3_idx, 0], x[c3_idx, 1], c='g', marker='x', label='Sandal')\n",
    "    plt.contourf(xx, yy, y_pred, alpha=0.3, cmap=plt.cm.brg)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = make_meshgrid(pca_data[:, 0], pca_data[:, 1])\n",
    "print(xx.shape, yy.shape)\n",
    "\n",
    "# plot(pca_data, label, y_pred, sv_idx, xx, yy, 'Linear SVM')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gaussian Mixture Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(\"./hw3.jpg\") as img:\n",
    "    image = img.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw3-wcjmnGUO-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3b57bcff566707e2aeacdf82598779b67125939b5e21814e41194bc40562bab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
